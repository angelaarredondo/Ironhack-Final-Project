{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca63a8b6",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on the Extracted Tweets (CeraVe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed80d3e",
   "metadata": {},
   "source": [
    "## 1 - Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3a170b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Angela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Angela\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de205f",
   "metadata": {},
   "source": [
    "## 2 - Import the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c2d8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This are tweets mentioning the brand together with other key words in the last five years\n",
    "# key words: \"review, quality, packaging, scam, works, animal, testing, cruelty, free, skin, recommend, scam\"\n",
    "larocheposay = pd.read_csv(\"tweets_Larocheposay.csv\")\n",
    "larocheposay = larocheposay.drop('Unnamed: 0', axis=1) # dropping a useless column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15535935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP TRIGRAMS AND BIGRAMS\n",
    "## BUSQUEDA DE PALABRAS CLAVE RELACIONADAS CON EL MUNDO DE LA COSMETICA \n",
    "## Y DE LA EMPRESA -- QUE PORCENTAJE SON MALOS? HAY ALGUNA ESPECIALMENTE MALA?\n",
    "## Usar tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc8e9c",
   "metadata": {},
   "source": [
    "## 3 - Conducting Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00660f42",
   "metadata": {},
   "source": [
    "### 3.1 - Prepare Textual Data for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f99bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Text cleaning\n",
    "def clean_up(s):\n",
    "    clean = re.sub(r'http\\S+', '', s)\n",
    "    return re.sub('[^A-Za-z ]+', ' ', clean).lower().strip()\n",
    "\n",
    "def clean_up2(s):\n",
    "    clean2 = re.sub(r'\\W*\\b\\w{1,3}\\b', '', s)\n",
    "    return re.sub('[^A-Za-z ]+', ' ', clean2).lower().strip()\n",
    "\n",
    "# 2 - Tokenization\n",
    "def tokenize(s):\n",
    "    return nltk.word_tokenize(s)\n",
    "\n",
    "# 3 - Stem and Lemmatize\n",
    "def stem_and_lemmatize(l):\n",
    "    ps = nltk.PorterStemmer()\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    list_words = []\n",
    "    \n",
    "    for w in l:\n",
    "        s = ps.stem(w)\n",
    "        s = lemmatizer.lemmatize(s)\n",
    "        list_words += [s] \n",
    "    return list_words\n",
    "\n",
    "# 4 - Stop words removal\n",
    "def remove_stopwords(l):\n",
    "    stop_words = stopwords.words('english')\n",
    "    return[w for w in l if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7446b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid errors, change type to string\n",
    "larocheposay['Tweet'] = larocheposay['Tweet'].apply(str)  # change to string for avoiding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5515d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:45:55+00:00</td>\n",
       "      <td>AomLeland88</td>\n",
       "      <td>[roche, posay, toleriane, ultra, face, makeup,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 23:45:07+00:00</td>\n",
       "      <td>SAlertPro</td>\n",
       "      <td>[roche, posay, substiane, riche, face, moistur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 23:07:37+00:00</td>\n",
       "      <td>zizzycarter</td>\n",
       "      <td>[care, much, scented, skincare, products, quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 22:18:24+00:00</td>\n",
       "      <td>lemkenxfhc</td>\n",
       "      <td>[roche, posay, toleriane, purifying, foaming, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 21:38:21+00:00</td>\n",
       "      <td>_titilay0_</td>\n",
       "      <td>[need, roche, posay, skin, starting, crack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2021-02-19 17:39:28+00:00</td>\n",
       "      <td>sevenjetc</td>\n",
       "      <td>[dannypsavage, five, minutes, need, save, mone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2021-02-19 16:51:02+00:00</td>\n",
       "      <td>izzatchubbz</td>\n",
       "      <td>[roche, posay, baume, whitecast, sikit, tekeju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2021-02-19 16:20:58+00:00</td>\n",
       "      <td>fritkis</td>\n",
       "      <td>[imspeaking, thinking, cucumber, rosemary, roc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2021-02-19 15:47:16+00:00</td>\n",
       "      <td>tyler_steele</td>\n",
       "      <td>[larocheposayusa, launched, save, skin, annual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2021-02-19 13:30:21+00:00</td>\n",
       "      <td>_Allsales</td>\n",
       "      <td>[reminder, starts, today, orders, free, hyalu,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date          User  \\\n",
       "0      2022-12-31 23:45:55+00:00   AomLeland88   \n",
       "1      2022-12-31 23:45:07+00:00     SAlertPro   \n",
       "2      2022-12-31 23:07:37+00:00   zizzycarter   \n",
       "3      2022-12-31 22:18:24+00:00    lemkenxfhc   \n",
       "4      2022-12-31 21:38:21+00:00    _titilay0_   \n",
       "...                          ...           ...   \n",
       "19995  2021-02-19 17:39:28+00:00     sevenjetc   \n",
       "19996  2021-02-19 16:51:02+00:00   izzatchubbz   \n",
       "19997  2021-02-19 16:20:58+00:00       fritkis   \n",
       "19998  2021-02-19 15:47:16+00:00  tyler_steele   \n",
       "19999  2021-02-19 13:30:21+00:00     _Allsales   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      [roche, posay, toleriane, ultra, face, makeup,...  \n",
       "1      [roche, posay, substiane, riche, face, moistur...  \n",
       "2      [care, much, scented, skincare, products, quit...  \n",
       "3      [roche, posay, toleriane, purifying, foaming, ...  \n",
       "4            [need, roche, posay, skin, starting, crack]  \n",
       "...                                                  ...  \n",
       "19995  [dannypsavage, five, minutes, need, save, mone...  \n",
       "19996  [roche, posay, baume, whitecast, sikit, tekeju...  \n",
       "19997  [imspeaking, thinking, cucumber, rosemary, roc...  \n",
       "19998  [larocheposayusa, launched, save, skin, annual...  \n",
       "19999  [reminder, starts, today, orders, free, hyalu,...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larocheposay['Tweet'] = larocheposay['Tweet'].apply(clean_up).apply(clean_up2).apply(tokenize).apply(remove_stopwords)\n",
    "larocheposay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99444259",
   "metadata": {},
   "source": [
    "### 3.2 - Get Polarity and Subjectivity of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c42092ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid problems\n",
    "larocheposay['Tweet'] = larocheposay['Tweet'].apply(str)\n",
    "tweet = larocheposay['Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3740bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get subjectivity\n",
    "def getSubjectivity(tweet):\n",
    "    return TextBlob(tweet).sentiment.subjectivity\n",
    "# Create a function to get polarity\n",
    "def getPolarity(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "# Create two new columns called 'Subjectivity' and 'Polarity'\n",
    "larocheposay['Subjectivity'] = larocheposay['Tweet'].apply(getSubjectivity)\n",
    "larocheposay['Polarity'] = larocheposay['Tweet'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3286ce8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:45:55+00:00</td>\n",
       "      <td>AomLeland88</td>\n",
       "      <td>['roche', 'posay', 'toleriane', 'ultra', 'face...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 23:45:07+00:00</td>\n",
       "      <td>SAlertPro</td>\n",
       "      <td>['roche', 'posay', 'substiane', 'riche', 'face...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 23:07:37+00:00</td>\n",
       "      <td>zizzycarter</td>\n",
       "      <td>['care', 'much', 'scented', 'skincare', 'produ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 22:18:24+00:00</td>\n",
       "      <td>lemkenxfhc</td>\n",
       "      <td>['roche', 'posay', 'toleriane', 'purifying', '...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 21:38:21+00:00</td>\n",
       "      <td>_titilay0_</td>\n",
       "      <td>['need', 'roche', 'posay', 'skin', 'starting',...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2021-02-19 17:39:28+00:00</td>\n",
       "      <td>sevenjetc</td>\n",
       "      <td>['dannypsavage', 'five', 'minutes', 'need', 's...</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2021-02-19 16:51:02+00:00</td>\n",
       "      <td>izzatchubbz</td>\n",
       "      <td>['roche', 'posay', 'baume', 'whitecast', 'siki...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2021-02-19 16:20:58+00:00</td>\n",
       "      <td>fritkis</td>\n",
       "      <td>['imspeaking', 'thinking', 'cucumber', 'rosema...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2021-02-19 15:47:16+00:00</td>\n",
       "      <td>tyler_steele</td>\n",
       "      <td>['larocheposayusa', 'launched', 'save', 'skin'...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2021-02-19 13:30:21+00:00</td>\n",
       "      <td>_Allsales</td>\n",
       "      <td>['reminder', 'starts', 'today', 'orders', 'fre...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date          User  \\\n",
       "0      2022-12-31 23:45:55+00:00   AomLeland88   \n",
       "1      2022-12-31 23:45:07+00:00     SAlertPro   \n",
       "2      2022-12-31 23:07:37+00:00   zizzycarter   \n",
       "3      2022-12-31 22:18:24+00:00    lemkenxfhc   \n",
       "4      2022-12-31 21:38:21+00:00    _titilay0_   \n",
       "...                          ...           ...   \n",
       "19995  2021-02-19 17:39:28+00:00     sevenjetc   \n",
       "19996  2021-02-19 16:51:02+00:00   izzatchubbz   \n",
       "19997  2021-02-19 16:20:58+00:00       fritkis   \n",
       "19998  2021-02-19 15:47:16+00:00  tyler_steele   \n",
       "19999  2021-02-19 13:30:21+00:00     _Allsales   \n",
       "\n",
       "                                                   Tweet  Subjectivity  \\\n",
       "0      ['roche', 'posay', 'toleriane', 'ultra', 'face...      0.000000   \n",
       "1      ['roche', 'posay', 'substiane', 'riche', 'face...      0.000000   \n",
       "2      ['care', 'much', 'scented', 'skincare', 'produ...      0.200000   \n",
       "3      ['roche', 'posay', 'toleriane', 'purifying', '...      0.566667   \n",
       "4      ['need', 'roche', 'posay', 'skin', 'starting',...      0.100000   \n",
       "...                                                  ...           ...   \n",
       "19995  ['dannypsavage', 'five', 'minutes', 'need', 's...      0.667857   \n",
       "19996  ['roche', 'posay', 'baume', 'whitecast', 'siki...      0.000000   \n",
       "19997  ['imspeaking', 'thinking', 'cucumber', 'rosema...      0.500000   \n",
       "19998  ['larocheposayusa', 'launched', 'save', 'skin'...      0.066667   \n",
       "19999  ['reminder', 'starts', 'today', 'orders', 'fre...      0.800000   \n",
       "\n",
       "       Polarity  \n",
       "0      0.000000  \n",
       "1      0.000000  \n",
       "2      0.200000  \n",
       "3      0.166667  \n",
       "4      0.000000  \n",
       "...         ...  \n",
       "19995  0.342857  \n",
       "19996  0.000000  \n",
       "19997  0.250000  \n",
       "19998  0.000000  \n",
       "19999  0.400000  \n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larocheposay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5a1bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the sentiment text\n",
    "def getSentiment(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7e86b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31 23:45:55+00:00</td>\n",
       "      <td>AomLeland88</td>\n",
       "      <td>['roche', 'posay', 'toleriane', 'ultra', 'face...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31 23:45:07+00:00</td>\n",
       "      <td>SAlertPro</td>\n",
       "      <td>['roche', 'posay', 'substiane', 'riche', 'face...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31 23:07:37+00:00</td>\n",
       "      <td>zizzycarter</td>\n",
       "      <td>['care', 'much', 'scented', 'skincare', 'produ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31 22:18:24+00:00</td>\n",
       "      <td>lemkenxfhc</td>\n",
       "      <td>['roche', 'posay', 'toleriane', 'purifying', '...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-31 21:38:21+00:00</td>\n",
       "      <td>_titilay0_</td>\n",
       "      <td>['need', 'roche', 'posay', 'skin', 'starting',...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2021-02-19 17:39:28+00:00</td>\n",
       "      <td>sevenjetc</td>\n",
       "      <td>['dannypsavage', 'five', 'minutes', 'need', 's...</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2021-02-19 16:51:02+00:00</td>\n",
       "      <td>izzatchubbz</td>\n",
       "      <td>['roche', 'posay', 'baume', 'whitecast', 'siki...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2021-02-19 16:20:58+00:00</td>\n",
       "      <td>fritkis</td>\n",
       "      <td>['imspeaking', 'thinking', 'cucumber', 'rosema...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2021-02-19 15:47:16+00:00</td>\n",
       "      <td>tyler_steele</td>\n",
       "      <td>['larocheposayusa', 'launched', 'save', 'skin'...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2021-02-19 13:30:21+00:00</td>\n",
       "      <td>_Allsales</td>\n",
       "      <td>['reminder', 'starts', 'today', 'orders', 'fre...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date          User  \\\n",
       "0      2022-12-31 23:45:55+00:00   AomLeland88   \n",
       "1      2022-12-31 23:45:07+00:00     SAlertPro   \n",
       "2      2022-12-31 23:07:37+00:00   zizzycarter   \n",
       "3      2022-12-31 22:18:24+00:00    lemkenxfhc   \n",
       "4      2022-12-31 21:38:21+00:00    _titilay0_   \n",
       "...                          ...           ...   \n",
       "19995  2021-02-19 17:39:28+00:00     sevenjetc   \n",
       "19996  2021-02-19 16:51:02+00:00   izzatchubbz   \n",
       "19997  2021-02-19 16:20:58+00:00       fritkis   \n",
       "19998  2021-02-19 15:47:16+00:00  tyler_steele   \n",
       "19999  2021-02-19 13:30:21+00:00     _Allsales   \n",
       "\n",
       "                                                   Tweet  Subjectivity  \\\n",
       "0      ['roche', 'posay', 'toleriane', 'ultra', 'face...      0.000000   \n",
       "1      ['roche', 'posay', 'substiane', 'riche', 'face...      0.000000   \n",
       "2      ['care', 'much', 'scented', 'skincare', 'produ...      0.200000   \n",
       "3      ['roche', 'posay', 'toleriane', 'purifying', '...      0.566667   \n",
       "4      ['need', 'roche', 'posay', 'skin', 'starting',...      0.100000   \n",
       "...                                                  ...           ...   \n",
       "19995  ['dannypsavage', 'five', 'minutes', 'need', 's...      0.667857   \n",
       "19996  ['roche', 'posay', 'baume', 'whitecast', 'siki...      0.000000   \n",
       "19997  ['imspeaking', 'thinking', 'cucumber', 'rosema...      0.500000   \n",
       "19998  ['larocheposayusa', 'launched', 'save', 'skin'...      0.066667   \n",
       "19999  ['reminder', 'starts', 'today', 'orders', 'fre...      0.800000   \n",
       "\n",
       "       Polarity Sentiment  \n",
       "0      0.000000   Neutral  \n",
       "1      0.000000   Neutral  \n",
       "2      0.200000  Positive  \n",
       "3      0.166667  Positive  \n",
       "4      0.000000   Neutral  \n",
       "...         ...       ...  \n",
       "19995  0.342857  Positive  \n",
       "19996  0.000000   Neutral  \n",
       "19997  0.250000  Positive  \n",
       "19998  0.000000   Neutral  \n",
       "19999  0.400000  Positive  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column to store the text sentiment\n",
    "larocheposay['Sentiment'] = larocheposay['Polarity'].apply(getSentiment)\n",
    "# Show the data\n",
    "larocheposay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb045cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    9874\n",
       "Neutral     8177\n",
       "Negative    1949\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larocheposay['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8b759ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "larocheposay.to_excel('larocheposay_clean.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c077850",
   "metadata": {},
   "source": [
    "### 3.3 - Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724229d",
   "metadata": {},
   "source": [
    "It will take a HUUUGE time to lost and it is time consuming. We have no time to loose so we will visualize the Data with Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe49cac2",
   "metadata": {},
   "source": [
    "## 4 - Sentiment Analysis of Bigram/Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4da95572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will explore word associations\n",
    "# N-Grams analysis are often used to see which words often show up together\n",
    "# N-Gram -- Contiguous sequence of n items from a given sample of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13a8f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d5ddd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = larocheposay['Tweet'].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a58bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec = CountVectorizer(stop_words=stoplist, ngram_range=(2,3))\n",
    "# Matrix of ngrams\n",
    "ngrams = c_vec.fit_transform(tweet)\n",
    "# Count frequency of ngrams\n",
    "count_values = ngrams.toarray().sum(axis=0)\n",
    "# List of NGrams\n",
    "vocab = c_vec.vocabulary_\n",
    "df_ngram = pd.DataFrame(sorted([(count_values[i],k) for k,i in vocab.items()], reverse=True)\n",
    "            ).rename(columns={0: 'frequency', 1:'bigram/trigram'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc6fa21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the sentiment analysis before, we can calculate the polarity and subjectivity for each bigram/trigram\n",
    "df_ngram['polarity'] = df_ngram['bigram/trigram'].apply(lambda x: TextBlob(x).polarity)\n",
    "df_ngram['subjective'] = df_ngram['bigram/trigram'].apply(lambda x: TextBlob(x).subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1ba753e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>bigram/trigram</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9717</td>\n",
       "      <td>roche posay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>744</td>\n",
       "      <td>roche posay anthelios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>744</td>\n",
       "      <td>posay anthelios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>694</td>\n",
       "      <td>posay effaclar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>678</td>\n",
       "      <td>roche posay effaclar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129446</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaah skin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129447</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaahhhhhhh roche posay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129448</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaahhhhhhh roche</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129449</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaaaa wait thnk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129450</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaaaa wait</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129451 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        frequency             bigram/trigram  polarity  subjective\n",
       "0            9717                roche posay       0.0         0.0\n",
       "1             744      roche posay anthelios       0.0         0.0\n",
       "2             744            posay anthelios       0.0         0.0\n",
       "3             694             posay effaclar       0.0         0.0\n",
       "4             678       roche posay effaclar       0.0         0.0\n",
       "...           ...                        ...       ...         ...\n",
       "129446          1                 aaaah skin       0.0         0.0\n",
       "129447          1  aaaaaahhhhhhh roche posay       0.0         0.0\n",
       "129448          1        aaaaaahhhhhhh roche       0.0         0.0\n",
       "129449          1    aaaaaaaaaaaaa wait thnk       0.0         0.0\n",
       "129450          1         aaaaaaaaaaaaa wait       0.0         0.0\n",
       "\n",
       "[129451 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4208a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the sentiment text\n",
    "def getSentiment(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d147f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>bigram/trigram</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjective</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9717</td>\n",
       "      <td>roche posay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>744</td>\n",
       "      <td>roche posay anthelios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>744</td>\n",
       "      <td>posay anthelios</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>694</td>\n",
       "      <td>posay effaclar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>678</td>\n",
       "      <td>roche posay effaclar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129446</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaah skin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129447</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaahhhhhhh roche posay</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129448</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaahhhhhhh roche</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129449</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaaaa wait thnk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129450</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaaaaaaaaaa wait</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129451 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        frequency             bigram/trigram  polarity  subjective Sentiment\n",
       "0            9717                roche posay       0.0         0.0   Neutral\n",
       "1             744      roche posay anthelios       0.0         0.0   Neutral\n",
       "2             744            posay anthelios       0.0         0.0   Neutral\n",
       "3             694             posay effaclar       0.0         0.0   Neutral\n",
       "4             678       roche posay effaclar       0.0         0.0   Neutral\n",
       "...           ...                        ...       ...         ...       ...\n",
       "129446          1                 aaaah skin       0.0         0.0   Neutral\n",
       "129447          1  aaaaaahhhhhhh roche posay       0.0         0.0   Neutral\n",
       "129448          1        aaaaaahhhhhhh roche       0.0         0.0   Neutral\n",
       "129449          1    aaaaaaaaaaaaa wait thnk       0.0         0.0   Neutral\n",
       "129450          1         aaaaaaaaaaaaa wait       0.0         0.0   Neutral\n",
       "\n",
       "[129451 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column to store the text sentiment\n",
    "df_ngram['Sentiment'] = df_ngram['polarity'].apply(getSentiment)\n",
    "# Show the data\n",
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e078070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     97047\n",
       "Positive    24663\n",
       "Negative     7741\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74d0f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.to_excel('laroche_ngram.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2324b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
